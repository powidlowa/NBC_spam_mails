{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lti3WORYZsmK"
   },
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eEoj1DOwZsmM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DtUaewx1ZsmP"
   },
   "outputs": [],
   "source": [
    "# Loading the data \n",
    "\n",
    "def load_data():\n",
    "    df = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "    df_for_tests = df.head()\n",
    "    \n",
    "    idx = np.arange(df.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    train_set_size = int(df.shape[0] * 0.8)\n",
    "\n",
    "    train_set = df.loc[idx[:train_set_size]]\n",
    "    test_set = df.loc[idx[train_set_size:]]\n",
    "    \n",
    "    return train_set, test_set, df_for_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ae4YTbLtZsmR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set, df_for_tests = load_data()\n",
    "print(df_for_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OZDyrOMZZsmV"
   },
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "\n",
    "def clean_data(message):\n",
    "    \n",
    "    message = message.casefold()\n",
    "    \n",
    "    myRange_1 = [str(x) for x in range(0, 10)]\n",
    "    myRange_2 = [chr(x) for x in range (97, 123)]  \n",
    "    myRange = myRange_1 + myRange_2 + [' '] + ['.']\n",
    "   \n",
    "    for i in message:\n",
    "        if i not in myRange:\n",
    "            message = message.replace(i, '  ')\n",
    "    \n",
    "    message = re.sub(' +', ' ', message)\n",
    "    message = message.replace('.','')\n",
    "    message = message.strip()\n",
    "    result = message\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "r96K1BnlZsmX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned:  doesn t get how to operate 667 after it lt gt won t or what\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Doesn\\'t get, how{to}% \\\\operate+66.7 :after[it]\"\" & lt;# & gt; won\\'t `or(what)'\n",
    "print('cleaned: ',clean_data(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gEFD2wuFZsma"
   },
   "outputs": [],
   "source": [
    "# Preparation data for model\n",
    "\n",
    "def prep_for_model(train_set, test_set):\n",
    "    \n",
    "    train_set_x = np.array(train_set.iloc[:,1])\n",
    "    buf = []\n",
    "    for i in train_set_x:\n",
    "        buf.append((clean_data(str(i))).split(' '))\n",
    "    train_set_x = buf\n",
    "    train_set_y = np.array (train_set.iloc[:,0])\n",
    "    \n",
    "    test_set_x = np.array(test_set.iloc[:,1])\n",
    "    buf = []\n",
    "    for i in test_set_x:\n",
    "        buf.append((clean_data(str(i))).split(' '))\n",
    "    test_set_x = buf\n",
    "    test_set_y = np.array (test_set.iloc[:,0])\n",
    "    \n",
    "    return train_set_x, train_set_y, test_set_x, test_set_y\n",
    "\n",
    "train_set_x, train_set_y, test_set_x, test_set_y = prep_for_model(train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bnNLInEBZsmc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham ['go', 'until', 'jurong', 'point', 'crazy', 'available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', 'cine', 'there', 'got', 'amore', 'wat']\n",
      "ham ['u', 'dun', 'say', 'so', 'early', 'hor', 'u', 'c', 'already', 'then', 'say']\n"
     ]
    }
   ],
   "source": [
    "a1, a2, b1, b2 = prep_for_model(df_for_tests.head(3), df_for_tests.tail(2))\n",
    "print(a2[0], a1[0])\n",
    "print(b2[0], b1[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "olXobIliZsmg"
   },
   "outputs": [],
   "source": [
    "# Check words in categories\n",
    "\n",
    "def categories_words(x_train, y_train):\n",
    "    \n",
    "    all_words_list = []\n",
    "    ham_words_list = []\n",
    "    spam_words_list = []\n",
    "    \n",
    "    all_words_list = np.array([item for sublist in x_train for item in sublist])\n",
    "\n",
    "    for i in range(len(y_train)):\n",
    "        if y_train[i] == 'ham':\n",
    "            ham_words_list.append(x_train[i])\n",
    "        else:\n",
    "            spam_words_list.append(x_train[i])\n",
    "    \n",
    "    ham_words_list = np.array([item for sublist in ham_words_list for item in sublist])\n",
    "    spam_words_list = np.array([item for sublist in spam_words_list for item in sublist])\n",
    "    \n",
    "    return all_words_list, ham_words_list, spam_words_list\n",
    "\n",
    "all_words_list_a1, ham_words_list_a1, spam_words_list_a1 = categories_words(a1, a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zCkJB-7TZsmj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first five \"ham\" words of a1:  ['go' 'until' 'jurong' 'point' 'crazy']\n"
     ]
    }
   ],
   "source": [
    "print('first five \"ham\" words of a1: ', ham_words_list_a1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LO7_8FEKZsmm"
   },
   "outputs": [],
   "source": [
    "class Naive_Bayes(object):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    alpha: int\n",
    "        The smoothing coeficient.\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        self.train_set_x = None\n",
    "        self.train_set_y = None\n",
    "        \n",
    "        self.all_words_list = []\n",
    "        self.ham_words_list = []\n",
    "        self.spam_words_list = []\n",
    "    \n",
    "    def fit(self, train_set_x, train_set_y):\n",
    "\n",
    "        self.all_words_list, self.ham_words_list, self.spam_words_list = categories_words (train_set_x, train_set_y)\n",
    "        \n",
    "        self.probsHam = {}\n",
    "        self.probsSpam = {}\n",
    "        \n",
    "        uniqueWords = np.unique(self.all_words_list)\n",
    "        \n",
    "        unique, counts = np.unique(self.ham_words_list, return_counts = True)\n",
    "        hamStat = dict(zip(unique, counts))\n",
    "        hamNum = len(self.ham_words_list)\n",
    "        hamAlpha = len(np.unique(self.ham_words_list))\n",
    "        \n",
    "        unique, counts = np.unique(self.spam_words_list, return_counts = True)\n",
    "        spamStat = dict(zip(unique, counts))\n",
    "        spamNum = len(self.spam_words_list)\n",
    "        spamAlpha = len(np.unique(self.spam_words_list))\n",
    "        \n",
    "        for i in uniqueWords:\n",
    "            \n",
    "            if i in hamStat.keys():\n",
    "                self.probsHam[i] = (hamStat[i]+self.alpha)/(hamNum + self.alpha*hamAlpha)\n",
    "            else:\n",
    "                self.probsHam[i] = (self.alpha)/(hamNum + self.alpha*hamAlpha)\n",
    "                \n",
    "            if i in spamStat.keys():\n",
    "                self.probsSpam[i] = (spamStat[i]+self.alpha)/(spamNum + self.alpha*spamAlpha) \n",
    "            else:\n",
    "                self.probsSpam[i] = (self.alpha)/(spamNum + self.alpha*spamAlpha) \n",
    "        \n",
    "    def predict(self, test_set_x):\n",
    "        \n",
    "        \n",
    "        prediction = []\n",
    "        bufHam = 1\n",
    "        bufSpam = 1\n",
    "        \n",
    "        pH = len(np.unique(self.ham_words_list))/len(np.unique(self.all_words_list))\n",
    "        pS = len(np.unique(self.spam_words_list))/len(np.unique(self.all_words_list))\n",
    "        print(pH, pS)\n",
    "        \n",
    "        \n",
    "        for mail in test_set_x:\n",
    "            for word in mail:\n",
    "                if word in self.probsHam.keys() and word in self.probsSpam.keys():\n",
    "                    bufHam = bufHam*self.probsHam[word]\n",
    "                    bufSpam = bufSpam*self.probsSpam[word] \n",
    "            bufHam = bufHam*pH\n",
    "            bufSpam = bufSpam*pS\n",
    "            if bufHam > bufSpam:\n",
    "                prediction.append(\"ham\")\n",
    "            else:\n",
    "                prediction.append(\"spam\")\n",
    "            \n",
    "            bufHam = 1\n",
    "            bufSpam = 1\n",
    "        \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "two70VtTZsmp"
   },
   "outputs": [],
   "source": [
    "a = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lFOgwc0eZsmr"
   },
   "outputs": [],
   "source": [
    "model = Naive_Bayes(alpha=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dh3_xodbZsmv"
   },
   "outputs": [],
   "source": [
    "model.fit(train_set_x, train_set_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0-zUCJU_Zsmy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7894411473788329 0.3317260138476756\n"
     ]
    }
   ],
   "source": [
    "y_predictions = model.predict(test_set_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KBFDdUdkZsm0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9811659192825112\n"
     ]
    }
   ],
   "source": [
    "actual = list(test_set_y)\n",
    "accuracy = (y_predictions == test_set_y).mean()\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "NBC.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
